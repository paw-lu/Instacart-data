{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System for Instacart\n",
    "### Collaborative filtering using Matrix Factorization for implicit feedback data using simple SVD largest k Singular values.\n",
    "The matrix factorization performed in this notebook Computes the largest k singular values/vectors for a sparse matrix. Based upon the Largest K singular Values we find top K Recommended item. We are using scipy.sparse.linalg library which implements SVD using ARPACK as an eigensolver on A.H * A or A * A.H, depending on which one is more efficient.\n",
    "Note: Datafiles are built from scratch in this notebook only if they don't exist on disk. However, to force rebuild any datafile, there will be a REBUILD_* constant in the respective cell that should be set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from numpy import bincount, log, sqrt\n",
    "import itertools\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting paths for data files\n",
    "base_path=\"\"\n",
    "product_user_matrix_path=base_path+\"product_user_matrix.npz\"\n",
    "order_products_prior_path=base_path+\"instacart_2017_05_01/order_products__prior.csv\"\n",
    "order_products_train_path=base_path+\"instacart_2017_05_01/order_products__train.csv\"\n",
    "orders_path=base_path+\"instacart_2017_05_01/orders.csv\"\n",
    "products_path=base_path+\"instacart_2017_05_01/products.csv\"\n",
    "test_data_path = base_path+'user_products__test.csv'\n",
    "matrix_df_path = base_path+\"user_products__prior.csv\"\n",
    "matrix_path = base_path+\"product_user_matrix.npz\"\n",
    "product_factor_50_path= base_path+\"product_factor_50.npy\"\n",
    "user_factor_50_path= base_path+\"user_factor_50.npy\"\n",
    "product_factor_100_path= base_path+\"product_factor_100.npy\"\n",
    "user_factor_100_path= base_path+\"user_factor_100.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order & User Datasets\n",
    "df_order_products_prior = pd.read_csv(\"instacart_2017_05_01/order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(order_products_train_path)\n",
    "df_orders = pd.read_csv(orders_path) \n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(products_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data ...\n",
      "Completed in 11.92s\n"
     ]
    }
   ],
   "source": [
    "def make_test_data(filepath, df_orders, df_order_products_train):\n",
    "    \"\"\"\n",
    "    Generates the test dataset and saves it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating test data ...\")\n",
    "\n",
    "    # Read train csv\n",
    "    df_order_user_current = df_orders.loc[(df_orders.eval_set == \"train\")].reset_index()\n",
    "    df_order_user_current = df_order_user_current[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # Sanity check #1: `current_order_user_df` and `df_order_products_train` should have the same number of \n",
    "    # unique order ids\n",
    "    assert len(df_order_user_current[\"order_id\"].unique()) == len(df_order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert train dataframe to a similar format\n",
    "    df_order_products_test = df_order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_products_test = df_order_products_test.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # Sanity check #2: `df_order_products_test` and `df_order_user_current` should have the same number of \n",
    "    # records before attempting to merge them\n",
    "    assert df_order_products_test.size == df_order_user_current.size\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_products_test = pd.merge(df_order_user_current, df_order_products_test, on=\"order_id\")\n",
    "    df_user_products_test = df_user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # Write to disk\n",
    "    df_user_products_test.to_csv(filepath, index_label=False)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Generate test data if it doesn't exist already\n",
    "REBUILD_TEST_DATA = False\n",
    "if REBUILD_TEST_DATA or not Path(test_data_path).is_file():\n",
    "    make_test_data(test_data_path, df_orders, df_order_products_train)\n",
    "\n",
    "df_user_products_test = pd.read_csv(test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[22963, 7963, 16589, 32792, 41787, 22825, 13640, 24852, 45066, 9387, 5450, 24838, 38547, 19019, 12007, 26352, 22559, 45613, 31883, 12324, 33957, 5699, 31612, 34284, 48523, 2361, 48821, 11913, 45645, 1757, 21329]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_products_test['products'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just making sure that the test data isn't corrupted\n",
    "assert len(df_user_products_test) == 131209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Dataframe for user-products-quantity for order_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating prior user product data frame ...\n",
      "Completed in 85.34s\n"
     ]
    }
   ],
   "source": [
    "def get_user_product_prior_df(filepath, df_orders, df_order_products_prior):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a dataframe of users and their prior products purchases, and writes it to disk at the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Creating prior user product data frame ...\")\n",
    "\n",
    "    df_merged = pd.merge(df_orders, df_order_products_prior, on=\"order_id\")\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    df_user_product_prior.to_csv(filepath, index_label=False)\n",
    "\n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "\n",
    "\n",
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "REBUILD_MATRIX_DF = False\n",
    "if REBUILD_MATRIX_DF or not Path(matrix_df_path).is_file():\n",
    "    get_user_product_prior_df(matrix_df_path, df_orders, df_order_products_prior)\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "# Making them as category for making dictonary of user and item ids later for easy \n",
    "# mapping from sparse Matrix representation\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    \"\"\"\n",
    "    Generates a utility matrix representing purchase history of users, and writes it to disk.\n",
    "    Rows and Columns represent products and users respectively.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Creating product user matrix ...\")\n",
    "\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>17122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>25133</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>26405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>30450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>35951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>38928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>39657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>41787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>46149</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>49235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1559</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>4071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>4957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>5322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>5450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>5869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307923</th>\n",
       "      <td>206209</td>\n",
       "      <td>23892</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307924</th>\n",
       "      <td>206209</td>\n",
       "      <td>23909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307925</th>\n",
       "      <td>206209</td>\n",
       "      <td>24852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307926</th>\n",
       "      <td>206209</td>\n",
       "      <td>25544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307927</th>\n",
       "      <td>206209</td>\n",
       "      <td>25837</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307928</th>\n",
       "      <td>206209</td>\n",
       "      <td>26209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307929</th>\n",
       "      <td>206209</td>\n",
       "      <td>26503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307930</th>\n",
       "      <td>206209</td>\n",
       "      <td>26634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307931</th>\n",
       "      <td>206209</td>\n",
       "      <td>28156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307932</th>\n",
       "      <td>206209</td>\n",
       "      <td>28590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307933</th>\n",
       "      <td>206209</td>\n",
       "      <td>31130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307934</th>\n",
       "      <td>206209</td>\n",
       "      <td>31477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307935</th>\n",
       "      <td>206209</td>\n",
       "      <td>33129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307936</th>\n",
       "      <td>206209</td>\n",
       "      <td>33351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307937</th>\n",
       "      <td>206209</td>\n",
       "      <td>36056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307938</th>\n",
       "      <td>206209</td>\n",
       "      <td>37654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307939</th>\n",
       "      <td>206209</td>\n",
       "      <td>38167</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307940</th>\n",
       "      <td>206209</td>\n",
       "      <td>38730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307941</th>\n",
       "      <td>206209</td>\n",
       "      <td>39216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307942</th>\n",
       "      <td>206209</td>\n",
       "      <td>40310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307943</th>\n",
       "      <td>206209</td>\n",
       "      <td>40396</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307944</th>\n",
       "      <td>206209</td>\n",
       "      <td>40534</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307945</th>\n",
       "      <td>206209</td>\n",
       "      <td>40992</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307946</th>\n",
       "      <td>206209</td>\n",
       "      <td>41213</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307947</th>\n",
       "      <td>206209</td>\n",
       "      <td>41665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307948</th>\n",
       "      <td>206209</td>\n",
       "      <td>43961</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307949</th>\n",
       "      <td>206209</td>\n",
       "      <td>44325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307950</th>\n",
       "      <td>206209</td>\n",
       "      <td>48370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307951</th>\n",
       "      <td>206209</td>\n",
       "      <td>48697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307952</th>\n",
       "      <td>206209</td>\n",
       "      <td>48742</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13307953 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id product_id  quantity\n",
       "0              1        196        10\n",
       "1              1      10258         9\n",
       "2              1      10326         1\n",
       "3              1      12427        10\n",
       "4              1      13032         3\n",
       "5              1      13176         2\n",
       "6              1      14084         1\n",
       "7              1      17122         1\n",
       "8              1      25133         8\n",
       "9              1      26088         2\n",
       "10             1      26405         2\n",
       "11             1      30450         1\n",
       "12             1      35951         1\n",
       "13             1      38928         1\n",
       "14             1      39657         1\n",
       "15             1      41787         1\n",
       "16             1      46149         3\n",
       "17             1      49235         2\n",
       "18             2         23         1\n",
       "19             2         79         1\n",
       "20             2       1559         6\n",
       "21             2       2002         4\n",
       "22             2       2573         2\n",
       "23             2       3151         1\n",
       "24             2       4071         1\n",
       "25             2       4957         1\n",
       "26             2       5212         1\n",
       "27             2       5322         1\n",
       "28             2       5450         1\n",
       "29             2       5869         1\n",
       "...          ...        ...       ...\n",
       "13307923  206209      23892         3\n",
       "13307924  206209      23909         1\n",
       "13307925  206209      24852         4\n",
       "13307926  206209      25544         1\n",
       "13307927  206209      25837         3\n",
       "13307928  206209      26209         1\n",
       "13307929  206209      26503         1\n",
       "13307930  206209      26634         1\n",
       "13307931  206209      28156         1\n",
       "13307932  206209      28590         1\n",
       "13307933  206209      31130         1\n",
       "13307934  206209      31477         1\n",
       "13307935  206209      33129         2\n",
       "13307936  206209      33351         1\n",
       "13307937  206209      36056         1\n",
       "13307938  206209      37654         1\n",
       "13307939  206209      38167         4\n",
       "13307940  206209      38730         1\n",
       "13307941  206209      39216         1\n",
       "13307942  206209      40310         1\n",
       "13307943  206209      40396         2\n",
       "13307944  206209      40534         2\n",
       "13307945  206209      40992         3\n",
       "13307946  206209      41213         7\n",
       "13307947  206209      41665         1\n",
       "13307948  206209      43961         3\n",
       "13307949  206209      44325         1\n",
       "13307950  206209      48370         1\n",
       "13307951  206209      48697         1\n",
       "13307952  206209      48742         2\n",
       "\n",
       "[13307953 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_product_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating product user matrix ...\n",
      "Completed in 9.92s\n"
     ]
    }
   ],
   "source": [
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "REBUILD_USER_MATRIX_DF = False\n",
    "if REBUILD_USER_MATRIX_DF or not Path(matrix_path).is_file():\n",
    "    build_product_user_matrix(matrix_path, df_user_product_prior)    \n",
    "product_user_matrix=sparse.load_npz(product_user_matrix_path).tocsr().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just making sure that the the generated matrix is accurates\n",
    "# User=1 bought product=196 10 times\n",
    "assert product_user_matrix[195, 0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x206209 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 716 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_user_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8700882953749"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# How sparse is the utility matrix?\n",
    "def sparsity(matrix):\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return(sparsity)\n",
    "\n",
    "sparsity(product_user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating User and product factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_factors_50,user_factors_50 here denote 50 latent Factors considered\n",
    "REBUILD_FACTORS= False\n",
    "if REBUILD_FACTORS or not ((Path(product_factor_50_path)).is_file() \n",
    "                           and (Path(user_factor_50_path)).is_file()): \n",
    "    #Calculating the product and user factors\n",
    "    product_factors_50, S, user_factors_50 = linalg.svds(product_user_matrix, 50)\n",
    "    # changing to user* factor format\n",
    "    user_factors_50=user_factors_50.T*S\n",
    "    # saving the user and product factors\n",
    "    np.save(product_factor_50_path, product_factors_50)\n",
    "    np.save(user_factor_50_path, user_factors_50)\n",
    "else:\n",
    "    # Loading the user and product factors \n",
    "    product_factors_50=np.load(product_factor_50_path)\n",
    "    user_factors_50=np.load(user_factor_50_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_factors_100,user_factors_100 here denotes 100 latent Factors considered\n",
    "REBUILD_FACTORS= False\n",
    "if REBUILD_FACTORS or not ((Path(product_factor_100_path)).is_file() \n",
    "                           and (Path(user_factor_100_path)).is_file()): \n",
    "    #Calculating the product and user factors\n",
    "    product_factors_100, S, user_factors_100 = linalg.svds(product_user_matrix, 100)\n",
    "    # changing to user* factor format\n",
    "    user_factors_100=user_factors_100.T*S\n",
    "    # saving the user and product factors\n",
    "    np.save(product_factor_100_path, product_factors_100)\n",
    "    np.save(user_factor_100_path, user_factors_100)\n",
    "else:\n",
    "    # Loading the user and product factors \n",
    "    product_factors_100=np.load(product_factor_100_path)\n",
    "    user_factors_100=np.load(user_factor_100_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class To find the top recommended items given a user_id\n",
    "class TopRecommended(object):\n",
    "    def __init__(self, product_factors,user_factors,product_user_matrix):\n",
    "        self.product_factors =product_factors\n",
    "        self.user_factors =user_factors\n",
    "        self.product_user_matrix=product_user_matrix\n",
    "    def recommend(self, user_id, N=10):\n",
    "        \n",
    "        \"\"\"\n",
    "        Finds top K Recommendations\n",
    "        \"\"\"\n",
    "        scores =  self.user_factors[user_id].dot(self.product_factors.T)\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        print(best)\n",
    "        print(scores[best])\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "\n",
    "    def recommend_new(self, user_id, N=10):\n",
    "        \"\"\"\n",
    "        Finds Top k new Recommendations\n",
    "        \"\"\"\n",
    "        scores =  self.user_factors[user_id].dot(self.product_factors.T)\n",
    "        bought_indices=product_user_matrix.T[user_id].nonzero()[1]\n",
    "        count = N + len(bought_indices)\n",
    "        ids = np.argpartition(scores, -count)[-count:]\n",
    "        best = sorted(zip(ids, scores[ids]), key=lambda x: -x[1])        \n",
    "        return list(itertools.islice((rec for rec in best if rec[0] not in bought_indices), N))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictonary to map User_id & Product_id in Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the utility matrix is 0-indexed, the below dict is required to convert between `ids` and `indices`.\n",
    "# For example, `product_id` 1 in the dataset is represented by the `0`th row of the utility matrix.\n",
    "\n",
    "# Maps user_id: user index\n",
    "u_dict = {uid:i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "\n",
    "# Maps product_index: product id\n",
    "p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing class for factors 50 which returns top recommended items for a user_id\n",
    "svd_recm=TopRecommended(product_factors_50,user_factors_50,product_user_matrix)\n",
    "\n",
    "# Initializing class for factors 100 which returns top recommended items for a user_id\n",
    "svd_recm_100=TopRecommended(product_factors_100,user_factors_100,product_user_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID : 1\n",
      "[32472 46139  6181 38920 13172   195 13571 31645 49224 37702]\n",
      "[1.1251277 1.2746832 2.9733458 2.1561556 1.9325018 4.8402205 1.643281\n",
      " 1.330689  1.8926625 1.8685513]\n"
     ]
    }
   ],
   "source": [
    "# Recommend items for a user 1\n",
    "user_id = 1\n",
    "print(\"User ID :\",user_id)\n",
    "# New Recommendations and Old Recommendations\n",
    "recommendations_all = svd_recm.recommend(u_dict[user_id],N=10)\n",
    "recommendations_new = svd_recm.recommend_new(u_dict[user_id],N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(195, 4.8402205),\n",
       " (6181, 2.9733458),\n",
       " (38920, 2.1561556),\n",
       " (13172, 1.9325018),\n",
       " (49224, 1.8926625),\n",
       " (37702, 1.8685513),\n",
       " (13571, 1.643281),\n",
       " (31645, 1.330689),\n",
       " (46139, 1.2746832),\n",
       " (32472, 1.1251277)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Products Bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual products bought by user 1\n",
      "['Soda', 'Organic String Cheese', '0% Greek Strained Yogurt', 'XL Pick-A-Size Paper Towel Rolls', 'Milk Chocolate Almonds', 'Pistachios', 'Cinnamon Toast Crunch', 'Aged White Cheddar Popcorn', 'Organic Whole Milk', 'Organic Half & Half', 'Zero Calorie Cola']\n",
      "\n",
      "\n",
      "All products recommended to user 1\n",
      "['Soda', 'Clementines', '0% Greek Strained Yogurt', 'Bag of Organic Bananas', 'Organic Half & Half', 'Trail Mix', 'Apples', 'Extra Fancy Unsalted Mixed Nuts', 'Zero Calorie Cola', 'Reduced Fat 2% Milk']\n",
      "\n",
      "\n",
      "New products recommended to user 1\n",
      "['Clementines', 'Trail Mix', 'Apples', 'Extra Fancy Unsalted Mixed Nuts', 'Reduced Fat 2% Milk', 'Sparkling Mineral Water', \"Crunchy Oats 'n Honey Granola Bars\", 'Mixed Fruit Fruit Snacks', 'Mozzarella String Cheese', 'Popcorn']\n"
     ]
    }
   ],
   "source": [
    "# Actual\n",
    "row = df_user_products_test.loc[df_user_products_test.user_id == user_id]\n",
    "actual = list(row[\"products\"])\n",
    "\n",
    "actual = actual[0][1:-1]\n",
    "actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "act_products = []\n",
    "for pid in actual:\n",
    "    act_products.extend((df_products.loc[df_products.product_id == pid].product_name).tolist())\n",
    "print(\"Actual products bought by user {}\\n{}\\n\\n\".format(user_id, act_products))\n",
    "\n",
    "# All Products Recommended \n",
    "all_recm_products=[]\n",
    "for recommend in recommendations_all:\n",
    "    all_recm_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_name).tolist())\n",
    "print(\"All products recommended to user {}\\n{}\\n\\n\".format(user_id, all_recm_products))\n",
    "\n",
    "\n",
    "# New Products Recommended \n",
    "new_recm_products=[]\n",
    "for recommend in recommendations_new:\n",
    "    new_recm_products.extend((df_products.loc[df_products.product_id == p_dict[recommend[0]]].product_name).tolist())\n",
    "print(\"New products recommended to user {}\\n{}\".format(user_id, new_recm_products))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_k_popular(k, df_order_products_prior):\n",
    "    popular_products = list(df_order_products_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose of the product_user utility matrix\n",
    "user_product_matrix = product_user_matrix.T.tocsr()\n",
    "\n",
    "# Number of recommendations to make for every user\n",
    "N_REC = 10\n",
    "\n",
    "# Get the `N_REC` most popular products\n",
    "popular_products = get_k_popular(N_REC, df_order_products_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(actual, pred):\n",
    "    \"\"\"\n",
    "    Given two lists representing actual and predicted values\n",
    "    Returns the recall of the prediction\n",
    "    \"\"\"\n",
    "    if len(actual) == 0:\n",
    "        return 0\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "\n",
    "def new_products(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the list of new products purchased\n",
    "    \"\"\"\n",
    "    actual = row[\"products\"][1:-1]  # Products purchased currently \n",
    "    actual = set([int(p.strip()) for p in actual.strip().split(\",\")])\n",
    "    liked = set([p_dict[i] for i in user_product_matrix[u_dict[row[\"user_id\"]]].indices])  # User's purchase history\n",
    "    return actual - liked  # Return only new products purchased\n",
    "\n",
    "\n",
    "def popular_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when popular products are recommended\n",
    "    \"\"\"\n",
    "    actual = new_products(row)\n",
    "    return recall_score(actual, popular_products)\n",
    "\n",
    "             \n",
    "def svd_recommend_50_new(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends new products\n",
    "    \"\"\"    \n",
    "    actual = new_products(row)\n",
    "    recommended = svd_recm.recommend_new(u_dict[row[\"user_id\"]], N=N_REC)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "def svd_recommend_100_new(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends new products\n",
    "    \"\"\"    \n",
    "    actual = new_products(row)\n",
    "    recommended = svd_recm_100.recommend_new(u_dict[row[\"user_id\"]], N=N_REC)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return recall_score(actual, recommended)\n",
    "\n",
    "\n",
    "             \n",
    "def build_eval_df(df_user_products_test, filepath=None, subset=None):\n",
    "    \"\"\"\n",
    "    Builds a dataframe of recall values of the baseline and our model for all the users\n",
    "    in the test data, and saves its to disk at `filepath`\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Building dataframe with recall values ...\")\n",
    "    \n",
    "    df_eval = df_user_products_test.copy()\n",
    "    if subset:\n",
    "        df_eval = df_eval.sample(n=int(len(df_eval) * subset), random_state=7)\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval[\"svd_new_score_50\"] = df_eval.apply(svd_recommend_50_new, axis=1)\n",
    "    df_eval[\"svd_new_score_100\"] = df_eval.apply(svd_recommend_100_new, axis=1)\n",
    "    df_eval.to_csv(filepath)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe with recall values ...\n",
      "Completed in -15887.73s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the dataframe with recall values of the baseline and the model\n",
    "REBUILD_EVAL_DF = True\n",
    "subset = 0.2  # Evaluate on `subset x 100`% of the test dataset\n",
    "eval_path = \"../data/eval/eval_discovery_svd_{}_{}.csv\".format(subset if subset is not None else \"full\", N_REC)\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    build_eval_df(df_user_products_test, filepath=eval_path, subset=subset)\n",
    "df_eval = pd.read_csv(eval_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD 100 Factor Model: 2.39%\n",
      "SVD 50 Factor Model: 2.84%\n",
      "Baseline: 2.62%\n"
     ]
    }
   ],
   "source": [
    "# Mean recall scores\n",
    "model_50_mean_recall,model_100_mean_recall, baseline_mean_recall = \\\n",
    "np.mean(df_eval[\"svd_new_score_50\"]),np.mean(df_eval[\"svd_new_score_100\"]), np.mean(df_eval[\"popular_score\"])\n",
    "print(\"SVD 100 Factor Model: {:.2f}%\".format(model_100_mean_recall * 100))\n",
    "print(\"SVD 50 Factor Model: {:.2f}%\".format(model_50_mean_recall * 100))\n",
    "print(\"Baseline: {:.2f}%\".format(baseline_mean_recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 50 factor SVD performs slightly better than the Baseline Model, but because of the overfitting in t the 100 Factors model their results are lower than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
